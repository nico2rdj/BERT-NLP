# BERT sur SQuAD 2.0

<p align="center" >

  ![bert](https://user-images.githubusercontent.com/22484369/73925375-3f426480-48ce-11ea-8f5d-bf92ab1ebe87.png)


</p>

<h3 align="center">
  üìÑ Diff√©rents Fine-Tuning de BERT sur le dataset SQuAD 2.0
</h3>
<p align="center">
  Projet NLP <br/>
  <small></small>
</p>

## Manuel d'utilisation

- Se placer √† la fin du jupyter notebook dans la cellule ci-dessous et mettre le paragraphe dans la variable doc et la question dans la variable q : 

![example](https://user-images.githubusercontent.com/22484369/73929430-11145300-48d5-11ea-8e14-a29becca0ff4.png)
 
    
   
    
    
    

## D√©tails de l'impl√©mentation de BERT


- Pour le preprocessing, nous avons utilis√© la libraire **transformers** avec la fonction **SquadV2Processor** pour r√©cup√©rer les questions et r√©ponses puis **squad_convert_examples_to_features** pour convertir les celles-ci en features que l'on donne en entr√©e de BERT. <br/>

Le format des entr√©es est le suivant : <br/>
![input](https://user-images.githubusercontent.com/22484369/73931543-c8f72f80-48d8-11ea-96e1-76f477e344f0.png)

 - Ces entr√©es repr√©sente : 
    - attention mask
    - entr√©e contenant la question et la r√©ponse sous forme id de token
    - position du d√©but de la r√©ponse
    - position de la fin de la r√©ponse

- Pour BERT, nous avons utilis√© l'architecture Fine-Tuned **BertForQuestionAnswering** de base avec des poids pr√©entra√Æn√©s 


![bert-ft](https://user-images.githubusercontent.com/22484369/73930902-a3b5f180-48d7-11ea-8145-b8a79f439229.png)



## Dataset: SQuAD 2.0
- Nous utilisons le dataset Squad 2.0 comportant un jeu de donn√©es de questions et de r√©ponses associ√©es. La grande particularit√© de ce dataset, et ce qui le diff√©rencie la premi√®re version de SQuAD, concerne la possibilit√© d'avoir une question sans r√©ponse. Il nous faut donc √† la fois trouver la position d'une r√©ponse dans un texte lorsqu'elle existe, mais aussi ne pas donner de r√©ponse lorsque la question n'en a pas. 

- Par cons√©quent, de simples mod√®les (ex: Bert) qui performent avec plus de 85% sur SQuAD doivent √™tre finetun√©s pour d√©passer les 66% sur SQuADv2

- Nous avons essay√© deux mod√®les diff√©rents en Fine Tuned la derni√®re couche:
  - L'un avec une couche Dense classique
  - L'autre avec une couche LSTM

## R√©sultats sur le dataset SQuAD 2.0
Pour les r√©sultats, nous avons compar√© plusieurs mod√®les sur plusieurs m√©triques, mais nous avons gard√© le F1 score afin de comparer au mieux nos r√©sultats. 

- Couche Dense classique: <br/>

Pour la couche Dense classique, comme nous l'avons dit pr√©c√©demment, les r√©sultats sont plus faibles sur SQuAD v2 avec un score de 66%. Cette couche n'est donc pas suffisante, nous avons donc d√©cid√© de tester d'autres mod√®les.

- LSTM: <br/>

Une id√©e, assez peu utilis√© mais qui peut s'averer pertinente est celle des LSTM. On obtient avec cette m√©thode un score de ...%. 

- CNN: <br/>

On a voulu utiliser un CNN en sortie de Bert, plus pr√©cis√©ment un CNN 1d, qui va prendre en entr√©e la concat√©nation des 4 derni√®res couches de Bert. Nous avons obtenu un score de ...% (en cours d'entrainement).

## License

- [MIT](LICENSE)

## Contributors
- Fares Embouazza
- Nicolas Martin
